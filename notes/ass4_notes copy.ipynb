{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8852dc-cc1d-4682-9195-0eb1f3288f3a",
   "metadata": {},
   "source": [
    "# Feature extraction using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52d9c481-2e98-48fd-9c7a-06b9f857b453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T18:58:30.188722Z",
     "iopub.status.busy": "2022-04-19T18:58:30.188221Z",
     "iopub.status.idle": "2022-04-19T18:58:30.200334Z",
     "shell.execute_reply": "2022-04-19T18:58:30.199540Z",
     "shell.execute_reply.started": "2022-04-19T18:58:30.188669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages - basics \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "# tf tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# image processsing\n",
    "from tensorflow.keras.preprocessing.image import (load_img,\n",
    "                                                  img_to_array,\n",
    "                                                  ImageDataGenerator)\n",
    "# VGG16 model\n",
    "from tensorflow.keras.applications.vgg16 import (preprocess_input,\n",
    "                                                 decode_predictions,\n",
    "                                                 VGG16)\n",
    "# layers\n",
    "from tensorflow.keras.layers import (Flatten, \n",
    "                                     Dense, \n",
    "                                     Dropout, \n",
    "                                     BatchNormalization)\n",
    "# generic model object\n",
    "from tensorflow.keras.models import Model\n",
    "# optimizers\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "#scikit-learn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478639e6-1ecd-4f80-aafd-3d340be56d68",
   "metadata": {},
   "source": [
    "## Plotting function (from last week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a0153a8-8003-4e9f-970d-bda83ad9b8f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T18:40:01.558147Z",
     "iopub.status.busy": "2022-04-19T18:40:01.558019Z",
     "iopub.status.idle": "2022-04-19T18:40:01.564573Z",
     "shell.execute_reply": "2022-04-19T18:40:01.564090Z",
     "shell.execute_reply.started": "2022-04-19T18:40:01.558127Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(H, epochs):\n",
    "    plt.style.use(\"seaborn-colorblind\")\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\", linestyle=\":\")\n",
    "    plt.title(\"Loss curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, epochs), H.history[\"val_accuracy\"], label=\"val_acc\", linestyle=\":\")\n",
    "    plt.title(\"Accuracy curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e622fd9-5246-4ca1-aa2a-52b30143ba00",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "757f80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = sorted(os.listdir(\"../data/images/train\"))\n",
    "# Remove '.DS_Store' if present\n",
    "if '.DS_Store' in classes:\n",
    "    classes.remove('.DS_Store')\n",
    "# Convert elements to lowercase\n",
    "classes = list(map(lambda x: x.lower(), classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8180f2",
   "metadata": {},
   "source": [
    "Showing a sample of images from each folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a650466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all the same so can be done the same below \n",
    "datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224,224)\n",
    "\n",
    "# Split the data into categories\n",
    "train_images = datagen.flow_from_directory(\n",
    "    \"../data/images/train\",\n",
    "    classes=classes,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42)\n",
    "\n",
    "# Split the data into categories\n",
    "val_images = datagen.flow_from_directory(\n",
    "    directory=\"../data/images/test\",\n",
    "    classes=classes,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e9263",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce0603-33c7-43cf-a008-a31a612e5219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T18:01:38.833749Z",
     "iopub.status.busy": "2022-04-19T18:01:38.833343Z",
     "iopub.status.idle": "2022-04-19T18:01:38.839212Z",
     "shell.execute_reply": "2022-04-19T18:01:38.838307Z",
     "shell.execute_reply.started": "2022-04-19T18:01:38.833727Z"
    }
   },
   "source": [
    "__Load VGG16 *without* the classification layers__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5063b7a-475a-49d1-a411-59a8a065fdb7",
   "metadata": {},
   "source": [
    "Here we're just loading the convolutional layers and not the final classification network, using the argument ```include_top=False```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f27b7f-79eb-435b-9519-4d042a520a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T18:40:16.084918Z",
     "iopub.status.busy": "2022-04-19T18:40:16.084429Z",
     "iopub.status.idle": "2022-04-19T18:40:16.393600Z",
     "shell.execute_reply": "2022-04-19T18:40:16.392758Z",
     "shell.execute_reply.started": "2022-04-19T18:40:16.084863Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, \n",
    "              pooling='avg',\n",
    "              input_shape=(32, 32, 3))\n",
    "\n",
    "# mark loaded layers as not trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# add new classifier layers - another way of adding layers - different than previous syntax we've seen before \n",
    "flat1 = Flatten()(model.layers[-1].output) \n",
    "class1 = Dense(128, activation='relu')(flat1) \n",
    "output = Dense(len(classes), activation='softmax')(class1) # Change here for how many labels there are - changed to len of classes \n",
    "\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, \n",
    "              outputs=output)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, \n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "sgd = SGD(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0f687-096f-43da-94ea-e2b6c9a3cb68",
   "metadata": {},
   "source": [
    "__Train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb24e5f-1687-46c8-829f-420bd0527909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T18:40:26.867690Z",
     "iopub.status.busy": "2022-04-19T18:40:26.867170Z",
     "iopub.status.idle": "2022-04-19T19:04:00.462962Z",
     "shell.execute_reply": "2022-04-19T19:04:00.461166Z",
     "shell.execute_reply.started": "2022-04-19T18:59:02.500606Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "H = model.fit(train_images,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=val_images,\n",
    "            #steps_per_epoch=train_images.samples // batch_size,\n",
    "            #validation_steps=val_images.samples // batch_size,\n",
    "            epochs=10,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461d6b6-3fc4-4951-be90-f37ca2678c22",
   "metadata": {},
   "source": [
    "__Evaluate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399b54f-d3f5-466c-a517-c182f625b045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T19:04:22.000252Z",
     "iopub.status.busy": "2022-04-19T19:04:21.999757Z",
     "iopub.status.idle": "2022-04-19T19:04:22.241606Z",
     "shell.execute_reply": "2022-04-19T19:04:22.241020Z",
     "shell.execute_reply.started": "2022-04-19T19:04:22.000197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the number is for the number of epochs \n",
    "plot_history(H, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e511487",
   "metadata": {},
   "source": [
    "The downward tragectory of the learning curve suggests that it have more to learn. No surprise since it was only a handful of epochs with not a lot of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc775896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283c38d",
   "metadata": {},
   "source": [
    "So accuracy is 44% in the test set which is 4% less than the validation accuracy during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965d5ff-3edd-472c-aa1f-5c91ed527ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T19:04:25.887858Z",
     "iopub.status.busy": "2022-04-19T19:04:25.887365Z",
     "iopub.status.idle": "2022-04-19T19:04:30.930497Z",
     "shell.execute_reply": "2022-04-19T19:04:30.929814Z",
     "shell.execute_reply.started": "2022-04-19T19:04:25.887803Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images, batch_size=32)\n",
    "print(classification_report(test_images.classes,\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=classes)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c13e8b",
   "metadata": {},
   "source": [
    "Accuracy is pretty terrible. Hoping for better with data augmentation to make dataset bigger. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3dd55-fa11-4792-8e20-767c527b6e5c",
   "metadata": {},
   "source": [
    "## Using data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e42f2a-81fa-4ace-bec4-78b14217b628",
   "metadata": {},
   "source": [
    "__Reload model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f99871",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f605dfd-c492-4a6d-9d3e-f8d99cee4a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T19:19:11.939269Z",
     "iopub.status.busy": "2022-04-19T19:19:11.938774Z",
     "iopub.status.idle": "2022-04-19T19:19:12.276631Z",
     "shell.execute_reply": "2022-04-19T19:19:12.276040Z",
     "shell.execute_reply.started": "2022-04-19T19:19:11.939215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, \n",
    "              pooling='avg',\n",
    "              weights='imagenet',\n",
    "              input_shape=(32, 32, 3))\n",
    "\n",
    "# mark loaded layers as not trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "bn = BatchNormalization()(flat1)            ## take the outputs (image embeddings) and normalize them \n",
    "class1 = Dense(256,                         ### only difference is adding this extra hidden layer \n",
    "               activation='relu')(bn)\n",
    "class2 = Dense(128, \n",
    "               activation='relu')(class1)\n",
    "output = Dense(len(classes), \n",
    "               activation='softmax')(class2)\n",
    "\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, \n",
    "              outputs=output)\n",
    "\n",
    "# compile\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "sgd = SGD(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# summarize\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc837883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # Define your layers here\n",
    "    # Example:\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8ad59-8ae8-4270-a466-ebc2e230d049",
   "metadata": {},
   "source": [
    "__Define data generator__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a295a14-fa67-4c94-ab7e-0c4a4ae6c3c2",
   "metadata": {},
   "source": [
    "You can see the documentation for ImageDataGenerator [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6218b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./ 255, rotation_range = 40, horizontal_flip = True, fill_mode = 'nearest', preprocessing_function = preprocess_input)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 40, horizontal_flip = True, fill_mode = 'nearest', preprocessing_function = preprocess_input)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_datagen.flow_from_directory(directory = train_data, batch_size = 32, target_size = (224,224), class_mode = \"categorical\", shuffle = False)\n",
    "val_images = val_datagen.flow_from_directory(directory = val_data, batch_size = 32, target_size = (224,224), class_mode = \"categorical\")\n",
    "test_images = test_datagen.flow_from_directory(directory = test_data, batch_size = 32, target_size = (224,224), class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b1f9d-d19a-45c7-b976-32f66ebe7094",
   "metadata": {},
   "source": [
    "We're choosing to generate data on the fly, rather than save it to a folder. This validation split labels some as training and some as validation which we use below when training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17f14c",
   "metadata": {},
   "source": [
    "__Train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "H = model.fit(train_images,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=val_images,\n",
    "            steps_per_epoch=train_images.samples // batch_size,\n",
    "            validation_steps=val_images.samples // batch_size,\n",
    "            epochs=10,\n",
    "            verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df796d8d-dc20-4e60-9b89-4ac999fbb130",
   "metadata": {},
   "source": [
    "__Inspect__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a52ea-38ec-429e-a121-6f62705d5bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T19:25:57.578025Z",
     "iopub.status.busy": "2022-04-19T19:25:57.577534Z",
     "iopub.status.idle": "2022-04-19T19:25:57.820903Z",
     "shell.execute_reply": "2022-04-19T19:25:57.820297Z",
     "shell.execute_reply.started": "2022-04-19T19:25:57.577971Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(H, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a78188",
   "metadata": {},
   "source": [
    "Still more epochs would help but does seem a bit better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad7ff0-6f15-49f4-943c-0f8ea9d3538c",
   "metadata": {},
   "source": [
    "__Evaluate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b29442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcab9b",
   "metadata": {},
   "source": [
    "accuracy has vastly improved when evaluating the test images but what does that mean when below it has barely improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5eadd-df2f-42bc-8535-470fa910ed1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T19:26:05.726153Z",
     "iopub.status.busy": "2022-04-19T19:26:05.725664Z",
     "iopub.status.idle": "2022-04-19T19:26:10.821945Z",
     "shell.execute_reply": "2022-04-19T19:26:10.821391Z",
     "shell.execute_reply.started": "2022-04-19T19:26:05.726098Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(val_images, batch_size=32)\n",
    "print(classification_report(val_images.classes,\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418bbad",
   "metadata": {},
   "source": [
    "Have only increased the f1/accuracy by 2% by adding a hidden layer and minor data augmentation. Mango is the serious struggle, the rest seem to be doing \"okay\" comparatively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d618b3",
   "metadata": {},
   "source": [
    "Have increased f1/accuracy by 5% by adding the batch normalization, adding one hidden layer and some minor data augmentation. Cats are the only category that is struggling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "  # load model without classifier layers\n",
    "model = VGG16(include_top=False, \n",
    "              pooling='avg',\n",
    "              input_shape=(32, 32, 3))\n",
    "# mark loaded layers as not trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "bn = BatchNormalization()(flat1)          \n",
    "class1 = Dense(256,                         \n",
    "              activation='relu')(bn)\n",
    "class2 = Dense(128, \n",
    "              activation='relu')(class1)\n",
    "output = Dense(len(classes), \n",
    "              activation='softmax')(class2)\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, \n",
    "              outputs=output)\n",
    "# compile\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "      initial_learning_rate=0.01,\n",
    "      decay_steps=10000,\n",
    "      decay_rate=0.9)\n",
    "sgd = SGD(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d7baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = sorted(os.listdir(\"../data/images/train\"))\n",
    "# Remove '.DS_Store' if present\n",
    "if '.DS_Store' in classes:\n",
    "    classes.remove('.DS_Store')\n",
    "# Convert elements to lowercase\n",
    "classes = list(map(lambda x: x.lower(), classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b3166ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_datagen = ImageDataGenerator(validation_split=0.2,\n",
    "                                horizontal_flip=True, \n",
    "                                rotation_range=20,  \n",
    "                                preprocessing_function = preprocess_input)\n",
    "    test_datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                                rotation_range=20,  \n",
    "                                preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e07eb032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1657 images belonging to 10 classes.\n",
      "Found 414 images belonging to 10 classes.\n",
      "Found 922 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224,224)\n",
    "# Training data\n",
    "train_images = train_datagen.flow_from_directory(\n",
    "    \"../data/images/train\",\n",
    "    classes=classes,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset=\"training\",\n",
    "    seed=42)\n",
    "# Validation data\n",
    "val_images = train_datagen.flow_from_directory(\n",
    "    directory=\"../data/images/train\",\n",
    "    classes=classes,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset=\"validation\",\n",
    "    seed=42)\n",
    "    # test data \n",
    "test_images = test_datagen.flow_from_directory(\n",
    "    \"../data/images/test\",\n",
    "    classes=classes,\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit(train_images,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=val_images,\n",
    "        steps_per_epoch=train_images.samples // batch_size,\n",
    "        validation_steps=val_images.samples // batch_size,\n",
    "        epochs=5,   ########## <-- adjust number here \n",
    "        verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f301a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb49f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_images.classes,\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=classes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8228e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = VGG16()\n",
    "# load model without classifier layers\n",
    "model2 = VGG16(include_top=False, \n",
    "            pooling='avg',\n",
    "            input_shape=(32, 32, 3))\n",
    "# mark loaded layers as not trainable\n",
    "for layer in model2.layers:\n",
    "    layer.trainable = False\n",
    "tf.keras.backend.clear_session()\n",
    "# add new classifier layers \n",
    "flat1 = Flatten()(model2.layers[-1].output) \n",
    "class1 = Dense(128, activation='relu')(flat1) \n",
    "output = Dense(15, activation='softmax')(class1) \n",
    "# define new model\n",
    "model2 = Model(inputs=model2.inputs, \n",
    "            outputs=output)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, \n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "sgd = SGD(learning_rate=lr_schedule)\n",
    "model2.compile(optimizer=sgd,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
